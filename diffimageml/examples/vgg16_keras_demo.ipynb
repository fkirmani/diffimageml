{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "vgg16_keras_demo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srodney/diffimageml/blob/main/diffimageml/examples/vgg16_keras_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds7N6ZWOvtkI"
      },
      "source": [
        "## Demo of the keras vgg16 implementation\n",
        "\n",
        "ML warmup: shows a demo classification of cats and dogs images from imagenet db.  See, for example: \n",
        "\n",
        "https://www.kaggle.com/shaochuanwang/keras-warm-up-cats-vs-dogs-cnn-with-vgg16\n",
        "\n",
        "https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDBCbMr4vtkO"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxmCXqxHBLUs"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, ZeroPadding2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers.core import Activation"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXEBlyLKvtkP"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNZo0-3k4Ud0"
      },
      "source": [
        "# Get the example image data\n",
        "\n",
        "## Option 1: from Google Drive (default)\n",
        "\n",
        "Grab the pre-fetched Kaggle zip file from a public Google Drive link.\n",
        "\n",
        "See the \"Fetch and set up the Data\" section below\n",
        "\n",
        "\n",
        "## Option 2: Get the data directly from Kaggle to Colab\n",
        "\n",
        "To get the training data directly from Kaggle to Google Colab, do the following:\n",
        "1. log in to Kaggle (register for an account if needed)\n",
        "2. Visit the Dogs vs Cats competition: https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "3. accept the competition rules (you must do this before you can download the data using the API)\n",
        "4. Follow the steps described here: https://www.kaggle.com/general/74235"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvQS_BKNCEo2"
      },
      "source": [
        "## Fetch and set up the data\n",
        "\n",
        "Here we download a zip file with the example training/validation and test data from Google Drive, unpack it, sort the data into subdirs by class, and load it into keras data generator objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq_WWBfpeVeN",
        "outputId": "2c3fac48-34f3-4288-c246-2d3624152906"
      },
      "source": [
        "# Grab the pre-fetched data from Google Drive\n",
        "# Gets placed into /content/dogs-vs-cats.zip\n",
        "zipfilename = \"/content/dogs-vs-cats.zip\"\n",
        "if os.path.isfile(zipfilename):\n",
        "  os.remove(zipfilename)\n",
        "!gdown --id 1xXZYJZkOzajQpHLPUvw9LzUq-zYIqbKa\n",
        "\n",
        "print(f\"Got zip file? {os.path.exists(zipfilename)}\")\n",
        "print(f\"File size = {os.stat(zipfilename).st_size} bytes\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xXZYJZkOzajQpHLPUvw9LzUq-zYIqbKa\n",
            "To: /content/dogs-vs-cats.zip\n",
            "852MB [00:13, 65.1MB/s]\n",
            "Got zip file? True\n",
            "File size = 851576689 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IReGFQUgRge",
        "outputId": "46686142-e23f-4e84-c4db-f111a883782e"
      },
      "source": [
        "# unzip the top-level zip file into a local Colab data directory\n",
        "datadir = \"dogs_vs_cats_data\"\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(datadir)\n",
        "\n",
        "# unzip the training/validation data : unpacks into a directory labeled 'train'\n",
        "trainzipfilepath = os.path.join(datadir, \"train.zip\")\n",
        "with zipfile.ZipFile(trainzipfilepath, 'r') as zip_ref:\n",
        "    zip_ref.extractall(datadir)\n",
        " \n",
        "traindatadir = os.path.join(datadir, \"train\")\n",
        "\n",
        "assert(os.path.exists(traindatadir))\n",
        "print(f\"Unpacked training data into {os.path.abspath(traindatadir)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unpacked training data into /content/dogs_vs_cats_data/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5P6YcSOyaTz",
        "outputId": "3dea8531-0fa6-4d1a-e113-34c6f7ad2af4"
      },
      "source": [
        "imagelist = glob.glob(traindatadir + '/*jpg')\n",
        "print(f\"Total Number of images = {len(imagelist)}\")\n",
        "\n",
        "# Sort the data into two sub-directories based on class\n",
        "classnames = [\"cat\", \"dog\"]\n",
        "for classname in classnames:\n",
        "  classdir = os.path.join(traindatadir, classname)\n",
        "  if not os.path.isdir(classdir):\n",
        "    os.mkdir(classdir)\n",
        "  classfilelist = glob.glob(traindatadir + f'/{classname}*jpg')\n",
        "  print(f\"Number of {classname} images = {len(classfilelist)}\")\n",
        "  for filename in classfilelist:\n",
        "    shutil.move(filename, classdir)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of images = 25000\n",
            "Number of cat images = 12500\n",
            "Number of dog images = 12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxMCySx4D_B3"
      },
      "source": [
        "# Set up the Data Generators\n",
        "\n",
        "Construct a data generator for training and validation, with an 80/20 split.\n",
        "\n",
        "Options below to adjust the image target image size, and to use image augmentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_61lbBbpyP9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69d5a49-074c-4380-d2eb-983d78e134d8"
      },
      "source": [
        "imagesize = 200 # pixels - fixing to square image arrays\n",
        "use_augmentation = False # set to true to include shifts and flip\n",
        "valsplit = 0.2  # fraction of available training data to use for validation\n",
        "\n",
        "# Create the data generator, with or without augmentation\n",
        "if use_augmentation:\n",
        "  datagen = ImageDataGenerator(rescale=1.0/255.0, width_shift_range=0.1, \n",
        "                               height_shift_range=0.1, horizontal_flip=True, \n",
        "                               validation_split=valsplit)\n",
        "else:    \n",
        "  datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=valsplit)\n",
        "\n",
        "\n",
        "print('Training data set (80%):')\n",
        "train_it = datagen.flow_from_directory(\n",
        "    directory=traindatadir, class_mode='binary', batch_size=64, \n",
        "    target_size=(imagesize, imagesize), subset='training')    \n",
        "\n",
        "print('\\n Validation data set (20%):')   \n",
        "test_it = datagen.flow_from_directory(\n",
        "    directory=traindatadir, class_mode='binary', batch_size=64, \n",
        "    target_size=(imagesize, imagesize), subset='validation')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data set (80%):\n",
            "Found 20000 images belonging to 2 classes.\n",
            "\n",
            " Validation data set (20%):\n",
            "Found 5000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkut9Lh93rtP"
      },
      "source": [
        "# Define Models\n",
        "\n",
        "These functions define three different CNNs:  a one-block, a two-block, and the VGG16 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn13D0rP3079"
      },
      "source": [
        "# define cnn model\n",
        "def define_model_1():\n",
        "    ##One Block CNN\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(imagesize, imagesize, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        " \n",
        "def define_model_1_dropout():\n",
        "    model = Sequential()\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(imagesize, imagesize, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "    \n",
        "def define_model_2():\n",
        "    \n",
        "    #Two Block CNN\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(imagesize, imagesize, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "    \n",
        "def VGG16():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(input_shape=(imagesize,imagesize,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
        "    model.add(Flatten(name='flatten'))\n",
        "    model.add(Dense(256, activation='relu', name='fc1'))\n",
        "    model.add(Dense(128, activation='relu', name='fc2'))\n",
        "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def VGG16_2():\n",
        "    model = Sequential()\n",
        "    \n",
        "  \n",
        "    model.add(ZeroPadding2D((1,1),input_shape=(imagesize,imagesize,3)))\n",
        "    model.add(Conv2D(2, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu'))  \n",
        "\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(2, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu'))     \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(4, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(4, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(8, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(8, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(8, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "    \n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid')) \n",
        "    \n",
        "    opt = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaoUeXKc4xQN"
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    plt.legend()\n",
        "    # save plot to file\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    plt.savefig(filename + '_plot.png')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "    # define model\n",
        "    model = VGG16_2()\n",
        "\n",
        "    # fit model\n",
        "    history = model.fit(train_it, validation_data=test_it, epochs=50, \n",
        "                        batch_size=32, verbose=1)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "    # learning curves\n",
        "    summarize_diagnostics(history)\n",
        "    \n",
        "    model.save('final_model.h5')\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6l3P4KE4x_-"
      },
      "source": [
        "# Run the model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4Ollq6U3-vj",
        "outputId": "ae95aeb0-a635-4de2-a6d3-735a282e4464"
      },
      "source": [
        "run_test_harness()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "313/313 [==============================] - 74s 234ms/step - loss: 0.6922 - accuracy: 0.5123 - val_loss: 0.6667 - val_accuracy: 0.6006\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.6601 - accuracy: 0.6089 - val_loss: 0.6202 - val_accuracy: 0.6566\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.6320 - accuracy: 0.6468 - val_loss: 0.6036 - val_accuracy: 0.6638\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 73s 233ms/step - loss: 0.6132 - accuracy: 0.6711 - val_loss: 0.5850 - val_accuracy: 0.6820\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 73s 233ms/step - loss: 0.5974 - accuracy: 0.6848 - val_loss: 0.5712 - val_accuracy: 0.7072\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.5834 - accuracy: 0.6959 - val_loss: 0.5503 - val_accuracy: 0.7156\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 72s 232ms/step - loss: 0.5662 - accuracy: 0.7125 - val_loss: 0.5456 - val_accuracy: 0.7222\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.5469 - accuracy: 0.7289 - val_loss: 0.5255 - val_accuracy: 0.7402\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.5378 - accuracy: 0.7369 - val_loss: 0.5264 - val_accuracy: 0.7396\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.5322 - accuracy: 0.7398 - val_loss: 0.5054 - val_accuracy: 0.7564\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 72s 230ms/step - loss: 0.5198 - accuracy: 0.7499 - val_loss: 0.4986 - val_accuracy: 0.7606\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.5111 - accuracy: 0.7547 - val_loss: 0.4925 - val_accuracy: 0.7628\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.5091 - accuracy: 0.7552 - val_loss: 0.4845 - val_accuracy: 0.7654\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.4949 - accuracy: 0.7619 - val_loss: 0.4811 - val_accuracy: 0.7736\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 72s 230ms/step - loss: 0.4969 - accuracy: 0.7646 - val_loss: 0.4812 - val_accuracy: 0.7636\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.4861 - accuracy: 0.7662 - val_loss: 0.4681 - val_accuracy: 0.7778\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.4808 - accuracy: 0.7681 - val_loss: 0.4753 - val_accuracy: 0.7702\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.4767 - accuracy: 0.7718 - val_loss: 0.4638 - val_accuracy: 0.7804\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.4680 - accuracy: 0.7787 - val_loss: 0.4601 - val_accuracy: 0.7838\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 72s 230ms/step - loss: 0.4613 - accuracy: 0.7861 - val_loss: 0.4553 - val_accuracy: 0.7856\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 72s 232ms/step - loss: 0.4518 - accuracy: 0.7889 - val_loss: 0.4586 - val_accuracy: 0.7862\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 72s 230ms/step - loss: 0.4544 - accuracy: 0.7914 - val_loss: 0.4435 - val_accuracy: 0.7930\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.4434 - accuracy: 0.7966 - val_loss: 0.4407 - val_accuracy: 0.7904\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 72s 230ms/step - loss: 0.4360 - accuracy: 0.8014 - val_loss: 0.4386 - val_accuracy: 0.7932\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 72s 230ms/step - loss: 0.4341 - accuracy: 0.8040 - val_loss: 0.4374 - val_accuracy: 0.8002\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 72s 230ms/step - loss: 0.4342 - accuracy: 0.8014 - val_loss: 0.4317 - val_accuracy: 0.7990\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 72s 230ms/step - loss: 0.4254 - accuracy: 0.8049 - val_loss: 0.4299 - val_accuracy: 0.8034\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.4221 - accuracy: 0.8049 - val_loss: 0.4288 - val_accuracy: 0.8026\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 73s 233ms/step - loss: 0.4179 - accuracy: 0.8145 - val_loss: 0.4283 - val_accuracy: 0.8046\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.4189 - accuracy: 0.8087 - val_loss: 0.4283 - val_accuracy: 0.8030\n",
            "Epoch 31/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.4101 - accuracy: 0.8125 - val_loss: 0.4224 - val_accuracy: 0.8052\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.3989 - accuracy: 0.8200 - val_loss: 0.4150 - val_accuracy: 0.8118\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - 72s 230ms/step - loss: 0.3892 - accuracy: 0.8263 - val_loss: 0.4141 - val_accuracy: 0.8102\n",
            "Epoch 34/50\n",
            "313/313 [==============================] - 72s 230ms/step - loss: 0.3943 - accuracy: 0.8230 - val_loss: 0.4225 - val_accuracy: 0.8134\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.3859 - accuracy: 0.8266 - val_loss: 0.4160 - val_accuracy: 0.8094\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.3757 - accuracy: 0.8339 - val_loss: 0.4216 - val_accuracy: 0.8102\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.3838 - accuracy: 0.8312 - val_loss: 0.4272 - val_accuracy: 0.8036\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - 72s 232ms/step - loss: 0.3762 - accuracy: 0.8334 - val_loss: 0.4048 - val_accuracy: 0.8196\n",
            "Epoch 39/50\n",
            "313/313 [==============================] - 73s 233ms/step - loss: 0.3708 - accuracy: 0.8396 - val_loss: 0.4055 - val_accuracy: 0.8190\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.3713 - accuracy: 0.8362 - val_loss: 0.4151 - val_accuracy: 0.8132\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.3670 - accuracy: 0.8398 - val_loss: 0.4014 - val_accuracy: 0.8190\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - 72s 232ms/step - loss: 0.3582 - accuracy: 0.8442 - val_loss: 0.4050 - val_accuracy: 0.8220\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - 72s 232ms/step - loss: 0.3493 - accuracy: 0.8489 - val_loss: 0.4036 - val_accuracy: 0.8212\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - 72s 229ms/step - loss: 0.3552 - accuracy: 0.8471 - val_loss: 0.4000 - val_accuracy: 0.8240\n",
            "Epoch 45/50\n",
            "313/313 [==============================] - 72s 232ms/step - loss: 0.3454 - accuracy: 0.8461 - val_loss: 0.4031 - val_accuracy: 0.8214\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - 73s 232ms/step - loss: 0.3420 - accuracy: 0.8520 - val_loss: 0.3959 - val_accuracy: 0.8242\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.3398 - accuracy: 0.8532 - val_loss: 0.4021 - val_accuracy: 0.8234\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.3301 - accuracy: 0.8547 - val_loss: 0.4082 - val_accuracy: 0.8190\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - 73s 233ms/step - loss: 0.3244 - accuracy: 0.8597 - val_loss: 0.4019 - val_accuracy: 0.8254\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - 72s 231ms/step - loss: 0.3209 - accuracy: 0.8607 - val_loss: 0.4003 - val_accuracy: 0.8270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> 82.700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dq5myS5Kti6"
      },
      "source": [
        " "
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}