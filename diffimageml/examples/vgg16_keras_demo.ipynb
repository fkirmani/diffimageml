{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "vgg16_keras_demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srodney/diffimageml/blob/main/diffimageml/examples/vgg16_keras_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds7N6ZWOvtkI"
      },
      "source": [
        "## Demo of the keras vgg16 implementation\n",
        "\n",
        "ML warmup: shows a demo classification of cats and dogs images from imagenet db.  See, for example: \n",
        "\n",
        "https://www.kaggle.com/shaochuanwang/keras-warm-up-cats-vs-dogs-cnn-with-vgg16\n",
        "\n",
        "https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDBCbMr4vtkO"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxmCXqxHBLUs"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, ZeroPadding2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers.core import Activation"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXEBlyLKvtkP"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNZo0-3k4Ud0"
      },
      "source": [
        "# Get the example image data\n",
        "\n",
        "## Option 1: from Google Drive (default)\n",
        "\n",
        "Grab the pre-fetched Kaggle zip file from a public Google Drive link.\n",
        "\n",
        "See the \"Fetch and set up the Data\" section below\n",
        "\n",
        "\n",
        "## Option 2: Get the data directly from Kaggle to Colab\n",
        "\n",
        "To get the training data directly from Kaggle to Google Colab, do the following:\n",
        "1. log in to Kaggle (register for an account if needed)\n",
        "2. Visit the Dogs vs Cats competition: https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "3. accept the competition rules (you must do this before you can download the data using the API)\n",
        "4. Follow the steps described here: https://www.kaggle.com/general/74235"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvQS_BKNCEo2"
      },
      "source": [
        "## Fetch and set up the data\n",
        "\n",
        "Here we download a zip file with the example training/validation and test data from Google Drive, unpack it, sort the data into subdirs by class, and load it into keras data generator objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq_WWBfpeVeN",
        "outputId": "78057dcc-6c7a-4c35-f787-c8ce4c9908c1"
      },
      "source": [
        "# Grab the pre-fetched data from Google Drive\n",
        "# Gets placed into /content/dogs-vs-cats.zip\n",
        "zipfilename = \"/content/dogs-vs-cats.zip\"\n",
        "if os.path.isfile(zipfilename):\n",
        "  os.remove(zipfilename)\n",
        "!gdown --id 1xXZYJZkOzajQpHLPUvw9LzUq-zYIqbKa\n",
        "\n",
        "print(f\"Got zip file? {os.path.exists(zipfilename)}\")\n",
        "print(f\"File size = {os.stat(zipfilename).st_size} bytes\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xXZYJZkOzajQpHLPUvw9LzUq-zYIqbKa\n",
            "To: /content/dogs-vs-cats.zip\n",
            "852MB [00:13, 65.1MB/s]\n",
            "Got zip file? True\n",
            "File size = 851576689 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IReGFQUgRge",
        "outputId": "9ecf04b5-2ad2-4bf0-db36-c22353da2b03"
      },
      "source": [
        "# unzip the top-level zip file into a local Colab data directory\n",
        "datadir = \"dogs_vs_cats_data\"\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(datadir)\n",
        "\n",
        "# unzip the training/validation data : unpacks into a directory labeled 'train'\n",
        "trainzipfilepath = os.path.join(datadir, \"train.zip\")\n",
        "with zipfile.ZipFile(trainzipfilepath, 'r') as zip_ref:\n",
        "    zip_ref.extractall(datadir)\n",
        " \n",
        "traindatadir = os.path.join(datadir, \"train\")\n",
        "\n",
        "assert(os.path.exists(traindatadir))\n",
        "print(f\"Unpacked training data into {os.path.abspath(traindatadir)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unpacked training data into /content/dogs_vs_cats_data/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5P6YcSOyaTz",
        "outputId": "addd3cc2-fe42-4acd-ddf0-77fa89bb6c8e"
      },
      "source": [
        "imagelist = glob.glob(traindatadir + '/*jpg')\n",
        "print(f\"Total Number of images = {len(imagelist)}\")\n",
        "\n",
        "# Sort the data into two sub-directories based on class\n",
        "classnames = [\"cat\", \"dog\"]\n",
        "for classname in classnames:\n",
        "  classdir = os.path.join(traindatadir, classname)\n",
        "  if not os.path.isdir(classdir):\n",
        "    os.mkdir(classdir)\n",
        "  classfilelist = glob.glob(traindatadir + f'/{classname}*jpg')\n",
        "  print(f\"Number of {classname} images = {len(classfilelist)}\")\n",
        "  for filename in classfilelist:\n",
        "    shutil.move(filename, classdir)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of images = 25000\n",
            "Number of cat images = 12500\n",
            "Number of dog images = 12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxMCySx4D_B3"
      },
      "source": [
        "# Set up the Data Generators\n",
        "\n",
        "Construct a data generator for training and validation, with an 80/20 split.\n",
        "\n",
        "Options below to adjust the image target image size, and to use image augmentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_61lbBbpyP9R",
        "outputId": "d9d92fc5-215e-4efa-d546-5196fa19f858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "imagesize = 200 # pixels - fixing to square image arrays\n",
        "use_augmentation = False # set to true to include shifts and flip\n",
        "valsplit = 0.2  # fraction of available training data to use for validation\n",
        "\n",
        "# Create the data generator, with or without augmentation\n",
        "if use_augmentation:\n",
        "  datagen = ImageDataGenerator(rescale=1.0/255.0, width_shift_range=0.1, \n",
        "                               height_shift_range=0.1, horizontal_flip=True, \n",
        "                               validation_split=valsplit)\n",
        "else:    \n",
        "  datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=valsplit)\n",
        "\n",
        "\n",
        "print('Training data set (80%):')\n",
        "train_it = datagen.flow_from_directory(\n",
        "    directory=traindatadir, class_mode='binary', batch_size=64, \n",
        "    target_size=(imagesize, imagesize), subset='training')    \n",
        "\n",
        "print('\\n Validation data set (20%):')   \n",
        "test_it = datagen.flow_from_directory(\n",
        "    directory=traindatadir, class_mode='binary', batch_size=64, \n",
        "    target_size=(imagesize, imagesize), subset='validation')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data set (80%):\n",
            "Found 20000 images belonging to 2 classes.\n",
            "\n",
            " Validation data set (20%):\n",
            "Found 5000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkut9Lh93rtP"
      },
      "source": [
        "# Define Models\n",
        "\n",
        "These functions define three different CNNs:  a one-block, a two-block, and the VGG16 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn13D0rP3079"
      },
      "source": [
        "# define cnn model\n",
        "def define_model_1():\n",
        "    ##One Block CNN\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(imagesize, imagesize, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        " \n",
        "def define_model_1_dropout():\n",
        "    model = Sequential()\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(imagesize, imagesize, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "    \n",
        "def define_model_2():\n",
        "    \n",
        "    #Two Block CNN\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(imagesize, imagesize, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "    \n",
        "def VGG16():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(input_shape=(imagesize,imagesize,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
        "    model.add(Flatten(name='flatten'))\n",
        "    model.add(Dense(256, activation='relu', name='fc1'))\n",
        "    model.add(Dense(128, activation='relu', name='fc2'))\n",
        "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def VGG16_2():\n",
        "    model = Sequential()\n",
        "    \n",
        "  \n",
        "    model.add(ZeroPadding2D((1,1),input_shape=(imagesize,imagesize,3)))\n",
        "    model.add(Conv2D(2, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu'))  \n",
        "\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(2, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu'))     \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(4, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(4, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(8, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(8, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(8, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Conv2D(16, (3, 3),padding='same'))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "    \n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Dense(128))\n",
        "    model.add(Activation('relu')) \n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid')) \n",
        "    \n",
        "    opt = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaoUeXKc4xQN"
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(history.history['loss'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('Classification Accuracy')\n",
        "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    plt.legend()\n",
        "    # save plot to file\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    plt.savefig(filename + '_plot.png')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "    # define model\n",
        "    model = VGG16_2()\n",
        "\n",
        "    # fit model\n",
        "    history = model.fit(train_it, validation_data=test_it, epochs=50, \n",
        "                        batch_size=32, verbose=1)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "    # learning curves\n",
        "    summarize_diagnostics(history)\n",
        "    \n",
        "    model.save('final_model.h5')\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6l3P4KE4x_-"
      },
      "source": [
        "# Run the model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4Ollq6U3-vj",
        "outputId": "dcbf3694-2853-4e6c-ddbf-da8b20bc2e43"
      },
      "source": [
        "run_test_harness()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "313/313 [==============================] - 99s 292ms/step - loss: 0.6928 - accuracy: 0.5082 - val_loss: 0.6840 - val_accuracy: 0.5778\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 89s 286ms/step - loss: 0.6763 - accuracy: 0.5736 - val_loss: 0.6393 - val_accuracy: 0.6264\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 89s 286ms/step - loss: 0.6387 - accuracy: 0.6236 - val_loss: 0.6232 - val_accuracy: 0.6358\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 89s 286ms/step - loss: 0.6224 - accuracy: 0.6426 - val_loss: 0.5980 - val_accuracy: 0.6742\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 89s 284ms/step - loss: 0.5999 - accuracy: 0.6741 - val_loss: 0.5781 - val_accuracy: 0.6836\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 89s 285ms/step - loss: 0.5789 - accuracy: 0.6931 - val_loss: 0.5724 - val_accuracy: 0.6980\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 89s 284ms/step - loss: 0.5701 - accuracy: 0.7031 - val_loss: 0.5613 - val_accuracy: 0.7072\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 89s 286ms/step - loss: 0.5648 - accuracy: 0.7078 - val_loss: 0.5512 - val_accuracy: 0.7142\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 90s 287ms/step - loss: 0.5523 - accuracy: 0.7165 - val_loss: 0.5437 - val_accuracy: 0.7256\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 90s 286ms/step - loss: 0.5489 - accuracy: 0.7203 - val_loss: 0.5339 - val_accuracy: 0.7320\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 89s 284ms/step - loss: 0.5373 - accuracy: 0.7342 - val_loss: 0.5236 - val_accuracy: 0.7374\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 89s 286ms/step - loss: 0.5241 - accuracy: 0.7396 - val_loss: 0.5273 - val_accuracy: 0.7372\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 90s 287ms/step - loss: 0.5204 - accuracy: 0.7419 - val_loss: 0.5157 - val_accuracy: 0.7458\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 90s 287ms/step - loss: 0.5155 - accuracy: 0.7496 - val_loss: 0.5195 - val_accuracy: 0.7418\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 90s 286ms/step - loss: 0.5111 - accuracy: 0.7511 - val_loss: 0.4970 - val_accuracy: 0.7606\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 90s 286ms/step - loss: 0.5000 - accuracy: 0.7588 - val_loss: 0.4923 - val_accuracy: 0.7582\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 89s 285ms/step - loss: 0.4987 - accuracy: 0.7576 - val_loss: 0.4939 - val_accuracy: 0.7606\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 89s 285ms/step - loss: 0.4923 - accuracy: 0.7660 - val_loss: 0.4993 - val_accuracy: 0.7650\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 90s 287ms/step - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.4766 - val_accuracy: 0.7738\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 89s 286ms/step - loss: 0.4771 - accuracy: 0.7724 - val_loss: 0.4853 - val_accuracy: 0.7702\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 89s 283ms/step - loss: 0.4736 - accuracy: 0.7788 - val_loss: 0.4742 - val_accuracy: 0.7750\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 88s 281ms/step - loss: 0.4698 - accuracy: 0.7806 - val_loss: 0.4604 - val_accuracy: 0.7864\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 88s 280ms/step - loss: 0.4592 - accuracy: 0.7865 - val_loss: 0.4678 - val_accuracy: 0.7770\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 88s 281ms/step - loss: 0.4578 - accuracy: 0.7825 - val_loss: 0.4542 - val_accuracy: 0.7836\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 89s 283ms/step - loss: 0.4506 - accuracy: 0.7941 - val_loss: 0.4530 - val_accuracy: 0.7876\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 89s 283ms/step - loss: 0.4431 - accuracy: 0.7979 - val_loss: 0.4608 - val_accuracy: 0.7820\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 88s 283ms/step - loss: 0.4455 - accuracy: 0.7921 - val_loss: 0.4478 - val_accuracy: 0.7946\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 88s 281ms/step - loss: 0.4274 - accuracy: 0.8014 - val_loss: 0.4422 - val_accuracy: 0.7998\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 88s 283ms/step - loss: 0.4282 - accuracy: 0.8069 - val_loss: 0.4397 - val_accuracy: 0.7986\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 88s 281ms/step - loss: 0.4216 - accuracy: 0.8079 - val_loss: 0.4333 - val_accuracy: 0.7996\n",
            "Epoch 31/50\n",
            " 63/313 [=====>........................] - ETA: 57s - loss: 0.4215 - accuracy: 0.8097"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dq5myS5Kti6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}